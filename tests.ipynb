{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from models.utils import load_model_and_state\n",
    "from datasets.CustomDataset import CustomImageDataset\n",
    "from datasets.transforms import get_transform\n",
    "from utils.visualization import denormalize\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ŁADOWANIE DANYCH\n",
    "img_set = 1\n",
    "color_mode = 'L'\n",
    "input_shape = (512, 512)\n",
    "\n",
    "transform = get_transform(color_mode, input_shape)\n",
    "\n",
    "# OBRAZY TRENINGOWE\n",
    "img_dirs = ['./data/train/set' + str(img_set)]\n",
    "dataset = CustomImageDataset(img_dirs=img_dirs, transform=transform, color_mode=color_mode)\n",
    "print(f\"Liczba obrazów w datasettie: {len(dataset)}\")\n",
    "data_loader = DataLoader(dataset, batch_size=8, shuffle=True, pin_memory=True, num_workers=0)\n",
    "\n",
    "# OBRAZY TESTOWE DO WYŚWIETLENIA WYNIKU\n",
    "print_img_dir = ['./data/test/set' + str(img_set)]\n",
    "print_dataset = CustomImageDataset(img_dirs=print_img_dir, transform=transform, color_mode=color_mode)\n",
    "print_loader = DataLoader(print_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# DLA PCA OBRAZY TRENINGOWE I TESTOWE\n",
    "train_img_dirs = ['./data/train/set' + str(img_set)]\n",
    "test_img_dirs = ['./data/test/set' + str(img_set)]\n",
    "\n",
    "# przygotowanie datasetów i DataLoaderów dla każdego folderu treningowego i testowego\n",
    "train_datasets = [CustomImageDataset(img_dirs=[img_dir], transform=transform, color_mode=color_mode) for img_dir in train_img_dirs]\n",
    "train_loaders = [DataLoader(dataset, batch_size=8, shuffle=True, pin_memory=True, num_workers=0) for dataset in train_datasets]\n",
    "\n",
    "test_datasets = [CustomImageDataset(img_dirs=[img_dir], transform=transform, color_mode=color_mode) for img_dir in test_img_dirs]\n",
    "test_loaders = [DataLoader(dataset, batch_size=8, shuffle=False) for dataset in test_datasets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBLICZENIE MEAN I STD DLA ZBIORU OBRAZÓW\n",
    "def mean_std_to_normalisation(dataset):\n",
    "    \"\"\"\n",
    "    Oblicza średnią i odchylenie standardowe dla zestawu obrazów w skali szarości.\n",
    "    \"\"\"\n",
    "    mean = np.mean(dataset)\n",
    "    std = np.std(dataset)\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "print(mean_std_to_normalisation(train_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przykładowe wyświetlenie kilku obrazów z augmentacji\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def show_images(images, nmax=4):\n",
    "#     fig, axs = plt.subplots(1, nmax, figsize=(15,15))\n",
    "#     for i in range(nmax):\n",
    "#         axs[i].imshow(images[i][0], cmap='gray')\n",
    "#         axs[i].axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "# data_iter = iter(data_loader)\n",
    "# images = next(data_iter)\n",
    "# show_images(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ŁADOWANIE MODELU\n",
    "model_path = './saved_models/ResCAE'\n",
    "device = 'cuda'\n",
    "model, optimizer, epoch = load_model_and_state(model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RYSUJ DLA DANYCH TRENINGOWYCH\n",
    "with torch.no_grad():\n",
    "    reconstructions = []\n",
    "    originals = []\n",
    "    count = 0\n",
    "    for data in data_loader:\n",
    "        if count >= 10:\n",
    "            break\n",
    "        data = data.to(device)\n",
    "        recon_batch = model(data)\n",
    "        reconstructions.append(recon_batch.cpu())\n",
    "        originals.append(data.cpu())\n",
    "        count += data.size(0)\n",
    "\n",
    "#print('Reconstruction min:', reconstructions[0].min().item(), 'max:', reconstructions[0].max().item())\n",
    "    \n",
    "# konkatenuj listy do tensorów dal 10 obrazów\n",
    "reconstructions = torch.cat(reconstructions)[:10] \n",
    "originals = torch.cat(originals)[:10]\n",
    "\n",
    "def plot_images(images, titles, mean, std, color_mode, figsize=(40, 8), denormalize_enable=False):\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)  # jeden wiersz\n",
    "\n",
    "    if denormalize_enable:\n",
    "        images = denormalize(images, mean, std)  # denormalizacja obrazów, jeśli aktywna\n",
    "\n",
    "    for i in range(n):\n",
    "        # przekształca obrazy kolorowe do formatu (wysokość, szerokość, kanały)\n",
    "        if images[i].ndim == 3 and images[i].shape[0] == 3:\n",
    "            image = images[i].permute(1, 2, 0)  # Zamiana osi (3, 512, 512) na (512, 512, 3)\n",
    "            axes[i].imshow(image)\n",
    "        else:\n",
    "            axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "        axes[i].set_title(titles[i])\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_aspect('equal')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()\n",
    "\n",
    "def plot_anomalies(originals, reconstructions, mean, std, color_mode, denormalize_enable=False):\n",
    "    n = 10\n",
    "    original_titles = [\"Original\"] * n\n",
    "    reconstruction_titles = [\"Reconstructed\"] * n\n",
    "\n",
    "    # wyświetlanie oryginalnych obrazów\n",
    "    plot_images(originals[:n], original_titles, mean, std, color_mode, denormalize_enable=denormalize_enable)\n",
    "\n",
    "    # wyświetlanie zrekonstruowanych obrazów\n",
    "    plot_images(reconstructions[:n], reconstruction_titles, mean, std, color_mode, denormalize_enable=denormalize_enable)\n",
    "\n",
    "\n",
    "if color_mode == \"RGB\":\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "else:\n",
    "    mean = [0.5]\n",
    "    std = [0.5]\n",
    "\n",
    "# wyświetlanie denormalizowanych obrazów\n",
    "plot_anomalies(originals, reconstructions, mean, std, color_mode, denormalize_enable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RYSUJ DLA DANYCH TESTOWYCH\n",
    "with torch.no_grad():\n",
    "    reconstructions_tests = []\n",
    "    tests = []\n",
    "    count = 0\n",
    "    for data in print_loader:\n",
    "        if count >= 10:\n",
    "            break\n",
    "        data = data.to(device)\n",
    "        recon_batch = model(data)\n",
    "        reconstructions_tests.append(recon_batch.cpu())\n",
    "        tests.append(data.cpu())\n",
    "        count += data.size(0)\n",
    "\n",
    "reconstructions_tests = torch.cat(reconstructions_tests)[:10]\n",
    "tests = torch.cat(tests)[:10]      \n",
    "\n",
    "def plot_images(images, titles, mean, std, color_mode, denormalize_enable, figsize=(40, 8)):\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)  # jeden wiersz\n",
    "\n",
    "    if denormalize_enable:\n",
    "        images = denormalize(images, mean, std)  # denormalizacja\n",
    "\n",
    "    for i in range(n):\n",
    "        if images[i].ndim == 3 and images[i].shape[0] == 3:\n",
    "            image = images[i].permute(1, 2, 0)\n",
    "            axes[i].imshow(image)\n",
    "        else:\n",
    "            axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "        axes[i].set_title(titles[i])\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_aspect('equal')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()\n",
    "\n",
    "def plot_anomalies(originals, reconstructions, mean, std, color_mode, denormalize_enable):\n",
    "    n = 10\n",
    "    original_titles = [\"Original\"] * n\n",
    "    reconstruction_titles = [\"Reconstructed\"] * n\n",
    "\n",
    "    # wyświetlanie oryginalnych obrazów\n",
    "    plot_images(originals[:n], original_titles, mean, std, color_mode, denormalize_enable)\n",
    "\n",
    "    # wyświetlanie rekonstruowanych obrazów\n",
    "    plot_images(reconstructions[:n], reconstruction_titles, mean, std, color_mode, denormalize_enable)\n",
    "\n",
    "def plot_results(originals, reconstructions, mean, std, color_mode, denormalize_enable):\n",
    "    if denormalize_enable:\n",
    "        originals = denormalize(originals, mean, std)\n",
    "        reconstructions = denormalize(reconstructions, mean, std)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 10, figsize=(40, 16))\n",
    "    for i in range(10):\n",
    "        if originals[i].ndim == 3 and originals[i].shape[0] == 3:\n",
    "            original_image = originals[i].permute(1, 2, 0)\n",
    "            reconstructed_image = reconstructions[i].permute(1, 2, 0)\n",
    "            axes[0, i].imshow(original_image)\n",
    "            axes[1, i].imshow(reconstructed_image)\n",
    "        else:\n",
    "            axes[0, i].imshow(originals[i].squeeze(), cmap='gray')\n",
    "            axes[1, i].imshow(reconstructions[i].squeeze(), cmap='gray')\n",
    "        \n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title('Original')\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title('Reconstruction')\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_differences(originals, reconstructions, mean, std, color_mode, denormalize_enable):\n",
    "    if denormalize_enable:\n",
    "        originals = denormalize(originals, mean, std)\n",
    "        reconstructions = denormalize(reconstructions, mean, std)\n",
    "    \n",
    "    differences = torch.abs(originals - reconstructions)\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(40, 8)) \n",
    "    for i in range(10):\n",
    "        if differences[i].ndim == 3 and differences[i].shape[0] == 3:\n",
    "            diff_img = differences[i].permute(1, 2, 0).cpu().numpy()\n",
    "            axes[i].imshow(diff_img)\n",
    "        else:\n",
    "            axes[i].imshow(differences[i].squeeze().cpu().numpy(), cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title('Difference')\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    plt.show()\n",
    "\n",
    "def plot_diff_on_original(originals, reconstructions, mean, std, color_mode, denormalize_enable, threshold=0.1):\n",
    "    if denormalize_enable:\n",
    "        originals = denormalize(originals, mean, std)\n",
    "        reconstructions = denormalize(reconstructions, mean, std)\n",
    "    \n",
    "    differences = torch.abs(originals - reconstructions)\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(40, 8))\n",
    "    for i in range(10):\n",
    "        original_img = originals[i].cpu().numpy()\n",
    "        diff_img = differences[i].cpu().numpy()\n",
    "        \n",
    "        if originals[i].ndim == 3 and originals[i].shape[0] == 3:\n",
    "            original_img = original_img.transpose(1, 2, 0)\n",
    "            diff_img = diff_img.transpose(1, 2, 0)\n",
    "        \n",
    "        if diff_img.max() > 0: # dla dzielenia przez 0\n",
    "            diff_img = (diff_img - diff_img.min()) / (diff_img.max() - diff_img.min())\n",
    "        \n",
    "        diff_img[diff_img < threshold] = 0\n",
    "        \n",
    "        if originals[i].ndim == 3 and originals[i].shape[0] == 3:\n",
    "            # dla kolorwych dodaje w kanale czerwonym\n",
    "            red_mask = np.zeros_like(original_img)\n",
    "            red_mask[..., 0] = diff_img[..., 0]\n",
    "            combined_img = np.clip(original_img + red_mask, 0, 1)\n",
    "        else:\n",
    "            # skala szarości- dodaje kanał czerwony\n",
    "            red_mask = np.zeros((original_img.shape[1], original_img.shape[2], 3))\n",
    "            red_mask[..., 0] = diff_img.squeeze()\n",
    "            combined_img = np.dstack([original_img.squeeze()] * 3)  # konwersja do RGB \n",
    "            combined_img = np.clip(combined_img + red_mask, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(combined_img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title('Diff on Original')\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    plt.show()\n",
    "\n",
    "def plot_ssim_heatmap(originals, reconstructions, mean, std, color_mode, denormalize_enable, threshold=None, win_size=11):\n",
    "    if denormalize_enable:\n",
    "        originals = denormalize(originals, mean, std)\n",
    "        reconstructions = denormalize(reconstructions, mean, std)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 10, figsize=(40, 8))\n",
    "    \n",
    "    for i in range(10):\n",
    "        original_img = originals[i].squeeze().cpu().numpy()\n",
    "        recon_img = reconstructions[i].squeeze().cpu().numpy()\n",
    "        \n",
    "        if color_mode == 'RGB':\n",
    "            original_img = np.transpose(original_img, (1, 2, 0))  # (C, H, W) -> (H, W, C)\n",
    "            recon_img = np.transpose(recon_img, (1, 2, 0))\n",
    "        \n",
    "        # obliczanie SSIM i mapy podobieństwa z podaniem data_range i rozmiaru kernela\n",
    "        ssim_value, ssim_map = ssim(original_img, recon_img, full=True, multichannel=(color_mode == 'RGB'), data_range=original_img.max() - original_img.min(), win_size=win_size)\n",
    "        \n",
    "        # tworzenie heatmapy z mapy SSIM\n",
    "        heatmap = 1 - ssim_map  # różnice jako 1 - SSIM\n",
    "        \n",
    "        # opcjonalne zastosowanie wartości progowej\n",
    "        if threshold is not None:\n",
    "            heatmap = np.where(heatmap > threshold, heatmap, 0)\n",
    "        \n",
    "        # znormalizowanie heatmapy do zakresu 0-1\n",
    "        heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
    "        \n",
    "        # wyświetlanie heatmapy z wybraną mapą kolorów\n",
    "        axes[i].imshow(heatmap, cmap='plasma')\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title('SSIM Heatmap')\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    plt.show()\n",
    "\n",
    "if color_mode == \"RGB\":\n",
    "    mean = [0.5, 0.5, 0.5]\n",
    "    std = [0.5, 0.5, 0.5]\n",
    "else:\n",
    "    mean = [0.5]\n",
    "    std = [0.5]\n",
    "\n",
    "\n",
    "denormalize_enable = False\n",
    "plot_anomalies(tests[:10], reconstructions_tests[:10], mean, std, color_mode, denormalize_enable)\n",
    "plot_differences(tests[:10], reconstructions_tests[:10], mean, std, color_mode, denormalize_enable)\n",
    "plot_diff_on_original(tests[:10], reconstructions_tests[:10], mean, std, color_mode, denormalize_enable, threshold=0.5)\n",
    "plot_ssim_heatmap(tests[:10], reconstructions_tests[:10], mean, std, color_mode, denormalize_enable, threshold=0.8, win_size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obliczenie PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "'''# Lista folderów z obrazami treningowymi\n",
    "train_img_dirs = [\n",
    "    './images/train', './images3/train', './images4/train', \n",
    "    './images5/train', './images6/train', './images7/train', \n",
    "    './images8/train', './images8/train2'\n",
    "]\n",
    "\n",
    "# Lista folderów z obrazami testowymi\n",
    "test_img_dirs = [\n",
    "    './images/test', './images3/test', './images4/test', \n",
    "    './images5/test', './images6/test', './images7/test', \n",
    "    './images8/test', './images8/test2'\n",
    "]'''\n",
    "\n",
    "dimms = 2\n",
    "\n",
    "# funkcja do wyodrębnienia przestrzeni latentnej\n",
    "def extract_latent_space(model, loader, device):\n",
    "    latent_space = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            _, z_mean, _ = model(data)\n",
    "            latent_space.append(z_mean.cpu().numpy())\n",
    "    return np.concatenate(latent_space, axis=0)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# wyodrębnienie przestrzeni latentnej dla zbiorów treningowych i testowych\n",
    "train_latent_spaces = [extract_latent_space(model, loader, device) for loader in train_loaders]\n",
    "test_latent_spaces = [extract_latent_space(model, loader, device) for loader in test_loaders]\n",
    "\n",
    "# redukcja wymiaru przy użyciu PCA\n",
    "pca = PCA(n_components=dimms)\n",
    "all_latent_spaces = np.concatenate(train_latent_spaces + test_latent_spaces, axis=0)\n",
    "pca.fit(all_latent_spaces)\n",
    "\n",
    "# przetworzenie przestrzeni latentnych dla zbiorów treningowych i testowych z osobna\n",
    "train_latent_spaces_pca = [pca.transform(latent_space) for latent_space in train_latent_spaces]\n",
    "test_latent_spaces_pca = [pca.transform(latent_space) for latent_space in test_latent_spaces]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wizualizacja wyników PCA w 2d/3D\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "\n",
    "# funkcja do rysowania wykresu 2D\n",
    "def plot_2d():\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    colors = ['blue', 'red', 'green', 'purple', 'orange', 'brown', 'pink', 'gray']\n",
    "\n",
    "    for idx, latent_space_pca in enumerate(train_latent_spaces_pca):\n",
    "        plt.scatter(latent_space_pca[:, 0], latent_space_pca[:, 1], s=10, alpha=0.6, label=f'Set {idx+1} Train', c=colors[idx], marker='o')\n",
    "    \n",
    "    for idx, latent_space_pca in enumerate(test_latent_spaces_pca):\n",
    "        plt.scatter(latent_space_pca[:, 0], latent_space_pca[:, 1], s=10, alpha=0.6, label=f'Set {idx+1} Test', c=colors[idx+1], marker='x')\n",
    "    \n",
    "    plt.title('Latent Space Visualization using PCA')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# funkcja do rysowania wykresu 3D\n",
    "def plot_3d():\n",
    "    colors = ['blue', 'red', 'green', 'purple', 'orange', 'brown', 'pink', 'gray']\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for idx, latent_space_pca in enumerate(train_latent_spaces_pca):\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=latent_space_pca[:, 0],\n",
    "            y=latent_space_pca[:, 1],\n",
    "            z=latent_space_pca[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(size=5, color=colors[idx]),\n",
    "            name=f'Set {idx+1} Train'\n",
    "        ))\n",
    "\n",
    "    for idx, latent_space_pca in enumerate(test_latent_spaces_pca):\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=latent_space_pca[:, 0],\n",
    "            y=latent_space_pca[:, 1],\n",
    "            z=latent_space_pca[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(size=5, color=colors[idx+1]),\n",
    "            name=f'Set {idx+1} Test'\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Latent Space Visualization using PCA',\n",
    "        scene=dict(\n",
    "            xaxis_title='Principal Component 1',\n",
    "            yaxis_title='Principal Component 2',\n",
    "            zaxis_title='Principal Component 3'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    pyo.plot(fig)\n",
    "\n",
    "# selektor rodzaju wykresu: 2D lub 3D\n",
    "if dimms == 2:\n",
    "    plot_2d()\n",
    "elif dimms == 3:\n",
    "    plot_3d()\n",
    "else:\n",
    "    print(\"Niepoprawny wybór. Wybierz '2D' lub '3D'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERUJE OBRAZ Z LOSOWEGO WEKTORA\n",
    "def generate_random_latent_vector(model, latent_dim):\n",
    "    # generowanie losowego wektora latentnego\n",
    "    random_latent_vector = torch.randn(1, latent_dim).to(\"cuda\")\n",
    "\n",
    "    # dekodowanie losowego wektora latentnego\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        reconstructed_image = model.decode(random_latent_vector)\n",
    "    \n",
    "    return reconstructed_image\n",
    "\n",
    "def show_generated_image(image):\n",
    "    image = denormalize(image, mean, std)\n",
    "    image = image.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image[0], cmap='gray')\n",
    "    plt.title('Generated Image from Random Latent Vector')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "latent_dim = 128\n",
    "# generowanie losowego wektora latentnego i rekonstrukcja obrazu\n",
    "reconstructed_image = generate_random_latent_vector(model, latent_dim)\n",
    "show_generated_image(reconstructed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIZUALIZACJA LATENT SPACE\n",
    "# dla zbiorów przestrzeni latenalnych wszstkich obrazów tworzy histogramy dla każdego wymiaru (waartość w wektorze od liczby wystąpień)\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# połączone dane latent spaces dla treningu i testu do wizualizacji\n",
    "combined_train_latent_spaces = np.concatenate(train_latent_spaces, axis=0)\n",
    "combined_test_latent_spaces = np.concatenate(test_latent_spaces, axis=0)\n",
    "\n",
    "# funkcja do wizualizacji wszystkich linii gęstości jedna pod drugą\n",
    "def plot_stacked_density_lines(latent_spaces, title):\n",
    "    num_dimensions = latent_spaces.shape[1]\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i in range(num_dimensions):\n",
    "        all_values = latent_spaces[:, i]\n",
    "        density, bins = np.histogram(all_values, bins=50, density=True)\n",
    "        bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "        offset = i * 10\n",
    "\n",
    "        # tworzenie linii gęstości z offsetem i kolorem według gęstości\n",
    "        for j in range(len(bin_centers) - 1):\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=[bin_centers[j], bin_centers[j+1]],\n",
    "                    y=[offset, offset],\n",
    "                    mode='lines',\n",
    "                    line=dict(color=f'rgba(0, 0, 255, {density[j] / density.max()})', width=10),\n",
    "                    showlegend=False\n",
    "                )\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='Value',\n",
    "        yaxis=dict(showticklabels=False),\n",
    "        width=2000, \n",
    "        height=10 * num_dimensions,  # wysokość wykresu\n",
    "        margin=dict(l=50, r=20, t=25, b=25)  # ustawienie marginesów\n",
    "    )\n",
    "\n",
    "    # zapisz wykres do pliku HTML\n",
    "    fig.write_html(f\"{title.replace(' ', '_').lower()}.html\")\n",
    "\n",
    "plot_stacked_density_lines(combined_train_latent_spaces, 'Train Latent Space Distribution')\n",
    "plot_stacked_density_lines(combined_test_latent_spaces, 'Test Latent Space Distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ŁADOWANIE DANYCH\n",
    "img_set = 2\n",
    "color_mode = 'L'\n",
    "input_shape = (512, 512)\n",
    "\n",
    "transform = get_transform(color_mode, input_shape)\n",
    "\n",
    "# OBRAZY TRENINGOWE\n",
    "train_img_dirs = ['./data/train/set' + str(img_set)]\n",
    "train_datasets = [CustomImageDataset(img_dirs=[img_dir], transform=transform, color_mode=color_mode) for img_dir in train_img_dirs]\n",
    "train_loaders = [DataLoader(dataset, batch_size=8, shuffle=True, pin_memory=True, num_workers=0) for dataset in train_datasets]\n",
    "\n",
    "# OBRAZY TESTOWE DO WYŚWIETLENIA WYNIKU\n",
    "test_img_dirs = ['./data/test/set' + str(img_set)]\n",
    "test_datasets = [CustomImageDataset(img_dirs=[img_dir], transform=transform, color_mode=color_mode) for img_dir in test_img_dirs]\n",
    "test_loaders = [DataLoader(dataset, batch_size=8, shuffle=False) for dataset in test_datasets]\n",
    "\n",
    "print(f\"Liczba obrazów w treningowym datasetcie: {len(train_datasets[0])}\")\n",
    "print(f\"Liczba obrazów w testowym datasetcie: {len(test_datasets[0])}\")\n",
    "\n",
    "# zbieranie latent vectors z danych treningowych\n",
    "latent_vectors = []\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for loader in train_loaders:\n",
    "        for batch in loader:\n",
    "            if isinstance(batch, (list, tuple)):\n",
    "                inputs = batch[0].to(device)\n",
    "            else:\n",
    "                inputs = batch.to(device)\n",
    "            \n",
    "            recon, mu, logvar, z = model(inputs)\n",
    "            latent_vectors.append(z.cpu())\n",
    "\n",
    "latent_vectors = torch.cat(latent_vectors, dim=0)\n",
    "mu_latent = torch.mean(latent_vectors, dim=0)\n",
    "cov_latent = torch.cov(latent_vectors.T)\n",
    "\n",
    "# konwersja na numpy\n",
    "mu_np = mu_latent.numpy()\n",
    "cov_np = cov_latent.numpy()\n",
    "\n",
    "# dodanie małej wartości do diagonalnej, aby zapewnić inwersję\n",
    "cov_np += np.eye(cov_np.shape[0]) * 1e-6\n",
    "\n",
    "# obliczenie odwrotności macierzy kowariancji\n",
    "try:\n",
    "    cov_inv = np.linalg.inv(cov_np)\n",
    "except np.linalg.LinAlgError:\n",
    "    # Jeśli macierz jest osobliwa, użyj pseudo-inwersji\n",
    "    cov_inv = np.linalg.pinv(cov_np)\n",
    "    print(\"Macierz kowariancji była osobliwa. Użyto pseudo-inwersji.\")\n",
    "\n",
    "def mahalanobis_distance(z, mu, cov_inv):\n",
    "    return distance.mahalanobis(z, mu, cov_inv)\n",
    "\n",
    "# obliczanie odległości dla danych treningowych\n",
    "training_distances = [mahalanobis_distance(z_i, mu_np, cov_inv) for z_i in latent_vectors.numpy()]\n",
    "\n",
    "# ustalanie progu anomalii (95 percentyl)\n",
    "threshold = np.percentile(training_distances, 95)\n",
    "print(f\"Próg anomalii: {threshold}\")\n",
    "\n",
    "# przetwarzanie danych testowych i wizualizacja\n",
    "with torch.no_grad():\n",
    "    for loader in test_loaders:\n",
    "        for batch in loader:\n",
    "            if isinstance(batch, (list, tuple)):\n",
    "                inputs = batch[1].to(device)\n",
    "            else:\n",
    "                inputs = batch.to(device)\n",
    "            \n",
    "            recon, mu, logvar, z = model(inputs)\n",
    "            z = z.cpu().numpy()\n",
    "            \n",
    "            # obliczenie odległości dla każdego wektora w batchu\n",
    "            anomaly_scores = [mahalanobis_distance(z_i, mu_np, cov_inv) for z_i in z]\n",
    "            \n",
    "            # wykrywanie anomalii\n",
    "            for idx, score in enumerate(anomaly_scores):\n",
    "                if score > threshold:\n",
    "                    status = \"Wykryto anomalię\"\n",
    "                else:\n",
    "                    status = \"Obraz jest normalny.\"\n",
    "                \n",
    "                print(f\"Obraz {idx+1}: {status} (Score: {score:.2f})\")\n",
    "            \n",
    "            # wizualizacja pierwszego obrazu w batchu\n",
    "            input_image = inputs[1].squeeze().cpu().numpy()\n",
    "            recon_image = recon[1].squeeze().cpu().numpy()\n",
    "            reconstruction_error = np.abs(input_image - recon_image)\n",
    "            normalized_error = (reconstruction_error - reconstruction_error.min()) / (reconstruction_error.max() - reconstruction_error.min() + 1e-8)\n",
    "            \n",
    "            plt.figure(figsize=(12, 4))\n",
    "            \n",
    "            # oryginalny obraz\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(input_image, cmap='gray')\n",
    "            plt.title('Obraz Wejściowy')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # rekonstrukcja\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(recon_image, cmap='gray')\n",
    "            plt.title('Rekonstrukcja')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # heatmapa anomalii\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(input_image, cmap='gray')\n",
    "            plt.imshow(normalized_error, cmap='hot', alpha=0.5)\n",
    "            plt.title('Mapa Anomalii')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # wizualizacja błędu jako oddzielny obraz\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(normalized_error, cmap='hot')\n",
    "            plt.title('Mapa Błędu Rekonstrukcji')\n",
    "            plt.colorbar()\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# funkcja straty SSIM\n",
    "def ssim_loss(recon_x, x, kernel_size=15):\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "\n",
    "    padding = kernel_size // 2\n",
    "    mu1 = F.avg_pool2d(recon_x, kernel_size, 1, padding)\n",
    "    mu2 = F.avg_pool2d(x, kernel_size, 1, padding)\n",
    "\n",
    "    sigma1 = F.avg_pool2d(recon_x ** 2, kernel_size, 1, padding) - mu1 ** 2\n",
    "    sigma2 = F.avg_pool2d(x ** 2, kernel_size, 1, padding) - mu2 ** 2\n",
    "    sigma12 = F.avg_pool2d(recon_x * x, kernel_size, 1, padding) - mu1 * mu2\n",
    "\n",
    "    ssim_n = (2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)\n",
    "    ssim_d = (mu1 ** 2 + mu2 ** 2 + C1) * (sigma1 + sigma2 + C2)\n",
    "    ssim = ssim_n / ssim_d\n",
    "\n",
    "    recon_loss = torch.clamp(( ssim) / 2, 0, 1)\n",
    "    return recon_loss\n",
    "\n",
    "# funkcja wizualizująca\n",
    "def visualize_reconstruction(recon_x, x, kernel_size=15):\n",
    "    with torch.no_grad():\n",
    "        ssim_map = ssim_loss(recon_x, x, kernel_size=kernel_size).cpu().numpy()\n",
    "\n",
    "\n",
    "    recon_x_np = recon_x[0].permute(1, 2, 0).cpu().numpy()\n",
    "    x_np = x[0].permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axs[0].imshow(x_np, cmap='gray')\n",
    "    axs[0].set_title(\"Oryginalny obraz\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(recon_x_np, cmap='gray')\n",
    "    axs[1].set_title(\"Zrekonstruowany obraz\")\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(1 - ssim_map[0, :, :], cmap='hot')\n",
    "    axs[2].set_title(\"Mapa błędu (1-SSIM)\")\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# funkcja wizualizująca z mapą błędu w kanale czerwonym\n",
    "def visualize_reconstruction_with_red_overlay(recon_x, x, kernel_size=11, threshold=None):\n",
    "    with torch.no_grad():\n",
    "        ssim_map = ssim_loss(recon_x, x, kernel_size=kernel_size).cpu().numpy()\n",
    "\n",
    "    recon_x_np = recon_x[0, 0].cpu().numpy()\n",
    "    x_np = x[0, 0].cpu().numpy()\n",
    "    ssim_map_np = 1 - ssim_map[0, 0]\n",
    "\n",
    "    # zastosowanie progu, jeśli podano\n",
    "    if threshold is not None:\n",
    "        ssim_map_np[ssim_map_np < (threshold)] = 0\n",
    "\n",
    "\n",
    "    x_normalized = (x_np - x_np.min()) / (x_np.max() - x_np.min())\n",
    "    ssim_map_normalized = (ssim_map_np - ssim_map_np.min()) / (ssim_map_np.max() - ssim_map_np.min())\n",
    "\n",
    "    overlay_image = np.stack([ssim_map_normalized, x_normalized, x_normalized], axis=-1)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axs[0].imshow(x_np, cmap='gray')\n",
    "    axs[0].set_title(\"Oryginalny obraz\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(recon_x_np, cmap='gray')\n",
    "    axs[1].set_title(\"Zrekonstruowany obraz\")\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(overlay_image)\n",
    "    axs[2].set_title(\"Mapa błędu w kanale czerwonym\")\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "image_index = 3\n",
    "img1 = tests[image_index].cpu().unsqueeze(0)\n",
    "img2 = reconstructions_tests[image_index].cpu().unsqueeze(0)\n",
    "\n",
    "visualize_reconstruction_with_red_overlay(img2, img1, kernel_size=21, threshold=.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
